{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Set up Huggingface pipeline for Meta LLaMA\n",
        "model_id = \"meta-llama/Llama-3.2-1B\"\n",
        "pipe_llama = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Set up Huggingface pipeline for GPT-2\n",
        "pipe_gpt2 = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# Generate text from both models\n",
        "result_llama_32 = pipe_llama(\"The key to life is\", max_length=50)[0]['generated_text']\n",
        "result_gpt2 = pipe_gpt2(\"The key to life is\", max_length=50)[0]['generated_text']\n",
        "print(f\"Llama 3.2-1B said: {result_llam_32}\")\n",
        "print(f\"GPT 2 said: {result_gpt2}\")\n",
        "# Reference text (modify as per your desired reference)\n",
        "reference_text = \"The key to life is maintaining balance in everything.\"\n",
        "\n",
        "# Tokenize reference and generated text\n",
        "reference = [nltk.word_tokenize(reference_text)]\n",
        "generated_llama_32 = nltk.word_tokenize(result_llama_32)\n",
        "generated_gpt2 = nltk.word_tokenize(result_gpt2)\n",
        "\n",
        "# Compute BLEU scores\n",
        "bleu_llama_32 = sentence_bleu(reference, generated_llama_32)\n",
        "bleu_gpt2 = sentence_bleu(reference, generated_gpt2)\n",
        "\n",
        "# Print BLEU scores\n",
        "print(f\"BLEU score for LLaMA: {bleu_llama_32}\")\n",
        "print(f\"BLEU score for GPT-2: {bleu_gpt2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0T9to1Sa6u3",
        "outputId": "79ae9e58-b92f-4b99-c1bb-e30668e26e8c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Llama 3.2-1B said: [{'generated_text': 'The key to life is to be happy. What does this mean? Is it the feeling of'}]\n",
            "GPT 2 said: The key to life is to look down and see it. And we can't fix things in this way. So to fix things in this way, we need to find ways to make things better, faster and better.\n",
            "\n",
            "That is why we\n",
            "BLEU score for LLaMA: 0.07294866882805394\n",
            "BLEU score for GPT-2: 0.07744617268988857\n"
          ]
        }
      ]
    }
  ]
}